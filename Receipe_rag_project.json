{
  "id": "c0c2b9b5-6d25-48fe-89b4-a978998f625a",
  "data": {
    "nodes": [
      {
        "id": "ChatInput-CHr6c",
        "type": "genericNode",
        "position": {
          "x": -755.0609290868315,
          "y": 453.07029398108136
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "hi",
                "display_name": "Text",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.post1"
          },
          "showNode": false,
          "type": "ChatInput",
          "id": "ChatInput-CHr6c"
        },
        "selected": true,
        "measured": {
          "width": 192,
          "height": 66
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-kVQPF",
        "type": "genericNode",
        "position": {
          "x": 1328.6920864074345,
          "y": 202.56387589450227
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.post1"
          },
          "showNode": false,
          "type": "ChatOutput",
          "id": "ChatOutput-kVQPF"
        },
        "selected": false,
        "measured": {
          "width": 192,
          "height": 66
        },
        "dragging": false
      },
      {
        "id": "Agent-TJ8WW",
        "type": "genericNode",
        "position": {
          "x": 847.2488666738581,
          "y": 149.11898718515715
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": true,
                "input_types": [
                  "Memory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "add_current_date_tool": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "add_current_date_tool",
                "value": true,
                "display_name": "Current Date",
                "advanced": true,
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "input_types": []
              },
              "agent_description": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_description",
                "value": "A helpful assistant with access to the following tools:",
                "display_name": "Agent Description [Deprecated]",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "Groq",
                "display_name": "Model Provider",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def to_toolkit(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=self.get_tool_name(), tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": []
              },
              "handle_parsing_errors": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "input_types": []
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              },
              "n_messages": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              },
              "order": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "input_types": []
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "input_types": []
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "system_prompt": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks.",
                "display_name": "Agent Instructions",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "input_types": []
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Groq API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "API key for the Groq API.",
                "real_time_refresh": true,
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "https://api.groq.com",
                "display_name": "Groq API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Output Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 1,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput",
                "input_types": []
              },
              "n": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "whisper-large-v3",
                  "llama-guard-3-8b",
                  "llama-3.2-1b-preview",
                  "gemma2-9b-it",
                  "llama-3.1-8b-instant",
                  "llama-3.3-70b-specdec",
                  "llama-3.3-70b-versatile",
                  "llama3-8b-8192",
                  "qwen-2.5-32b",
                  "whisper-large-v3-turbo",
                  "llama-3.2-3b-preview",
                  "distil-whisper-large-v3-en",
                  "deepseek-r1-distill-qwen-32b",
                  "llama-3.2-11b-vision-preview",
                  "mixtral-8x7b-32768",
                  "qwen-2.5-coder-32b",
                  "deepseek-r1-distill-llama-70b",
                  "llama3-70b-8192",
                  "llama-3.2-90b-vision-preview"
                ],
                "options_metadata": [],
                "combobox": true,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama-3.2-1b-preview",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "real_time_refresh": false,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "input_types": []
              },
              "tool_model_enabled": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_model_enabled",
                "value": false,
                "display_name": "Enable Tool Models",
                "advanced": true,
                "dynamic": false,
                "info": "Select if you want to use models that can work with tools. If yes, only those models will be shown.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "input_types": []
              }
            },
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "icon": "bot",
            "base_classes": [
              "Message"
            ],
            "display_name": "Receipe_Chef",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "Agent",
          "id": "Agent-TJ8WW"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 631
        },
        "dragging": false
      },
      {
        "id": "Prompt-iTxIw",
        "type": "genericNode",
        "position": {
          "x": 377.37535290437415,
          "y": 159.3234296100534
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Your goal is to answer the questions from company data base, use RAG to fecth the details and provide most relavant output.\n\nQuestion:{question}\n\nin your response, Incorporate the receipe points: {results}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "question",
                "display_name": "question",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "results": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "results",
                "display_name": "results",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "question",
                "results"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-iTxIw"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 425
        },
        "dragging": false
      },
      {
        "id": "ParseDataFrame-T7lTT",
        "type": "genericNode",
        "position": {
          "x": -18.440088080769655,
          "y": 659.9822314414389
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "df": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "df",
                "value": "",
                "display_name": "DataFrame",
                "advanced": false,
                "input_types": [
                  "DataFrame"
                ],
                "dynamic": false,
                "info": "The DataFrame to convert to text rows.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataFrameInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import DataFrameInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataFrameComponent(Component):\n    display_name = \"Parse DataFrame\"\n    description = (\n        \"Convert a DataFrame into plain text following a specified template. \"\n        \"Each column in the DataFrame is treated as a possible template key, e.g. {col_name}.\"\n    )\n    icon = \"braces\"\n    name = \"ParseDataFrame\"\n\n    inputs = [\n        DataFrameInput(name=\"df\", display_name=\"DataFrame\", info=\"The DataFrame to convert to text rows.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=(\n                \"The template for formatting each row. \"\n                \"Use placeholders matching column names in the DataFrame, for example '{col1}', '{col2}'.\"\n            ),\n            value=\"{text}\",\n        ),\n        StrInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String that joins all row texts when building the single Text output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text\",\n            name=\"text\",\n            info=\"All rows combined into a single text, each row formatted by the template and separated by `sep`.\",\n            method=\"parse_data\",\n        ),\n    ]\n\n    def _clean_args(self):\n        dataframe = self.df\n        template = self.template or \"{text}\"\n        sep = self.sep or \"\\n\"\n        return dataframe, template, sep\n\n    def parse_data(self) -> Message:\n        \"\"\"Converts each row of the DataFrame into a formatted string using the template.\n\n        then joins them with `sep`. Returns a single combined string as a Message.\n        \"\"\"\n        dataframe, template, sep = self._clean_args()\n\n        lines = []\n        # For each row in the DataFrame, build a dict and format\n        for _, row in dataframe.iterrows():\n            row_dict = row.to_dict()\n            text_line = template.format(**row_dict)  # e.g. template=\"{text}\", row_dict={\"text\": \"Hello\"}\n            lines.append(text_line)\n\n        # Join all lines with the provided separator\n        result_string = sep.join(lines)\n        self.status = result_string  # store in self.status for UI logs\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "String that joins all row texts when building the single Text output.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template for formatting each row. Use placeholders matching column names in the DataFrame, for example '{col1}', '{col2}'.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert a DataFrame into plain text following a specified template. Each column in the DataFrame is treated as a possible template key, e.g. {col_name}.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse DataFrame",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "df",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseDataFrame",
          "id": "ParseDataFrame-T7lTT"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 337
        },
        "dragging": false
      },
      {
        "id": "File-n6y94",
        "type": "genericNode",
        "position": {
          "x": -2378.419128735457,
          "y": -52.98563970285531
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "file_path": {
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "",
                "display_name": "Server File Path",
                "advanced": true,
                "input_types": [
                  "Data",
                  "Message"
                ],
                "dynamic": false,
                "info": "Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "path": {
                "trace_as_metadata": true,
                "file_path": "c0c2b9b5-6d25-48fe-89b4-a978998f625a/2025-02-17_16-36-23_ThaiRecipes.pdf",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "zip",
                  "tar",
                  "tgz",
                  "bz2",
                  "gz"
                ],
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "",
                "display_name": "Path",
                "advanced": false,
                "dynamic": false,
                "info": "Supported file extensions: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data import BaseFileComponent\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.io import BoolInput, IntInput\nfrom langflow.schema import Data\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of individual or zipped text files.\n\n    This component supports processing multiple valid files within a zip archive,\n    resolving paths, validating file types, and optionally using multithreading for processing.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Load a file to be used in your project.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    inputs = [\n        *BaseFileComponent._base_inputs,\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent._base_outputs,\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Processes files either sequentially or in parallel, depending on concurrency settings.\n\n        Args:\n            file_list (list[BaseFileComponent.BaseFile]): List of files to process.\n\n        Returns:\n            list[BaseFileComponent.BaseFile]: Updated list of files with merged data.\n        \"\"\"\n\n        def process_file(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            \"\"\"Processes a single file and returns its Data object.\"\"\"\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                msg = f\"File not found: {file_path}. Error: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                msg = f\"Unexpected error processing {file_path}: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_count = len(file_list)\n\n        parallel_processing_threshold = 2\n        if concurrency < parallel_processing_threshold or file_count < parallel_processing_threshold:\n            if file_count > 1:\n                self.log(f\"Processing {file_count} files sequentially.\")\n            processed_data = [process_file(str(file.path), silent_errors=self.silent_errors) for file in file_list]\n        else:\n            self.log(f\"Starting parallel processing of {file_count} files with concurrency: {concurrency}.\")\n            file_paths = [str(file.path) for file in file_list]\n            processed_data = parallel_load_data(\n                file_paths,\n                silent_errors=self.silent_errors,\n                load_function=process_file,\n                max_concurrency=concurrency,\n            )\n\n        # Use rollup_basefile_data to merge processed data with BaseFile objects\n        return self.rollup_data(file_list, processed_data)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "concurrency_multithreading": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "concurrency_multithreading",
                "value": 1,
                "display_name": "Processing Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "When multiple files are being processed, the number of files to process concurrently.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "delete_server_file_after_processing": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "delete_server_file_after_processing",
                "value": true,
                "display_name": "Delete Server File After Processing",
                "advanced": true,
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "ignore_unspecified_files": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ignore_unspecified_files",
                "value": false,
                "display_name": "Ignore Unspecified Files",
                "advanced": true,
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "ignore_unsupported_extensions": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ignore_unsupported_extensions",
                "value": true,
                "display_name": "Ignore Unsupported Extensions",
                "advanced": true,
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "silent_errors": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "use_multithreading": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_multithreading",
                "value": true,
                "display_name": "[Deprecated] Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Load a file to be used in your project.",
            "icon": "file-text",
            "base_classes": [
              "Data"
            ],
            "display_name": "File",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_files",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "path",
              "file_path",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "File",
          "id": "File-n6y94"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 229
        },
        "dragging": false
      },
      {
        "id": "SplitText-uoR9j",
        "type": "genericNode",
        "position": {
          "x": -2023.0984711827382,
          "y": -55.00740287971681
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data, DataFrame\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = [_input.to_lc_document() for _input in self.data_inputs if isinstance(_input, Data)]\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.split_text())\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "\n",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "SplitText",
            "score": 0.0006561452663029057,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "SplitText",
          "id": "SplitText-uoR9j"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 512
        },
        "dragging": false
      },
      {
        "id": "NVIDIAEmbeddingsComponent-dJRxN",
        "type": "genericNode",
        "position": {
          "x": -1636.620205250767,
          "y": -52.83891291203423
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "base_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "https://integrate.api.nvidia.com/v1",
                "display_name": "NVIDIA Base URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.field_typing import Embeddings\nfrom langflow.inputs.inputs import DropdownInput, SecretStrInput\nfrom langflow.io import FloatInput, MessageTextInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass NVIDIAEmbeddingsComponent(LCEmbeddingsModel):\n    display_name: str = \"NVIDIA Embeddings\"\n    description: str = \"Generate embeddings using NVIDIA models.\"\n    icon = \"NVIDIA\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"nvidia/nv-embed-v1\",\n                \"snowflake/arctic-embed-I\",\n            ],\n            value=\"nvidia/nv-embed-v1\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"NVIDIA Base URL\",\n            refresh_button=True,\n            value=\"https://integrate.api.nvidia.com/v1\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"nvidia_api_key\",\n            display_name=\"NVIDIA API Key\",\n            info=\"The NVIDIA API Key.\",\n            advanced=False,\n            value=\"NVIDIA_API_KEY\",\n            required=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"base_url\" and field_value:\n            try:\n                build_model = self.build_embeddings()\n                ids = [model.id for model in build_model.available_models]\n                build_config[\"model\"][\"options\"] = ids\n                build_config[\"model\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the Nvidia model.\"\n            raise ImportError(msg) from e\n        try:\n            output = NVIDIAEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n                nvidia_api_key=self.nvidia_api_key,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to NVIDIA API. Error: {e}\"\n            raise ValueError(msg) from e\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "nvidia/nv-embedqa-mistral-7b-v2",
                  "nvidia/nv-embed-v1",
                  "baai/bge-m3",
                  "NV-Embed-QA",
                  "nvidia/embed-qa-4",
                  "nvidia/nv-embedqa-e5-v5",
                  "nvidia/llama-3.2-nv-embedqa-1b-v1",
                  "snowflake/arctic-embed-l"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "baai/bge-m3",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "nvidia_api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "nvidia_api_key",
                "value": "",
                "display_name": "NVIDIA API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The NVIDIA API Key.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "temperature": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Model Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate embeddings using NVIDIA models.",
            "icon": "NVIDIA",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "NVIDIA Embeddings",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "hidden": null,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "base_url",
                  "model",
                  "nvidia_api_key"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "model",
              "base_url",
              "nvidia_api_key",
              "temperature"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "embeddings",
            "key": "NVIDIAEmbeddingsComponent",
            "score": 0.000052003277518821525,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "NVIDIAEmbeddingsComponent",
          "id": "NVIDIAEmbeddingsComponent-dJRxN"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 399
        },
        "dragging": false
      },
      {
        "id": "AstraDB-4xL8y",
        "type": "genericNode",
        "position": {
          "x": -1208.2234930143622,
          "y": -47.00196208550142
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "embedding_model": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_model",
                "value": "",
                "display_name": "Embedding Model",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Specify the Embedding Model. Not required for Astra Vectorize collections.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "advanced_search_filter": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "advanced_search_filter",
                "value": {},
                "display_name": "Search Metadata Filter",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "api_endpoint": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [],
                "options_metadata": [],
                "combobox": true,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_endpoint",
                "value": "https://3c2b3c61-1161-40c2-b703-d22eaa69b8e5-us-east-2.apps.astra.datastax.com",
                "display_name": "Database",
                "advanced": false,
                "dynamic": false,
                "info": "The Database / API Endpoint for the Astra DB instance.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "astradb_vectorstore_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "astradb_vectorstore_kwargs",
                "value": {},
                "display_name": "AstraDBVectorStore Parameters",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of additional parameters for the AstraDBVectorStore.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "autodetect_collection": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "autodetect_collection",
                "value": false,
                "display_name": "Autodetect Collection",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to autodetect the collection.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\n\nfrom astrapy import AstraDBAdmin, DataAPIClient, Database\nfrom langchain_astradb import AstraDBVectorStore, CollectionVectorServiceOptions\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import FloatInput, NestedDictInput\nfrom langflow.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\nfrom langflow.utils.version import get_version_info\n\n\nclass AstraDBVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Ingest and search documents in Astra DB\"\n    documentation: str = \"https://docs.datastax.com/en/langflow/astra-components.html\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vector_store: AstraDBVectorStore | None = None\n\n    @dataclass\n    class NewDatabaseInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"description\": \"Create a new database in Astra DB.\",\n                        \"display_name\": \"Create New Database\",\n                        \"field_order\": [\"new_database_name\", \"cloud_provider\", \"region\"],\n                        \"template\": {\n                            \"new_database_name\": StrInput(\n                                name=\"new_database_name\",\n                                display_name=\"New Database Name\",\n                                info=\"Name of the new database to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"cloud_provider\": DropdownInput(\n                                name=\"cloud_provider\",\n                                display_name=\"Cloud Provider\",\n                                info=\"Cloud provider for the new database.\",\n                                options=[\"Amazon Web Services\", \"Google Cloud Platform\", \"Microsoft Azure\"],\n                                required=True,\n                            ),\n                            \"region\": DropdownInput(\n                                name=\"region\",\n                                display_name=\"Region\",\n                                info=\"Region for the new database.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    @dataclass\n    class NewCollectionInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"description\": \"Create a new collection in Astra DB.\",\n                        \"display_name\": \"Create New Collection\",\n                        \"field_order\": [\n                            \"new_collection_name\",\n                            \"embedding_generation_provider\",\n                            \"embedding_generation_model\",\n                        ],\n                        \"template\": {\n                            \"new_collection_name\": StrInput(\n                                name=\"new_collection_name\",\n                                display_name=\"New Collection Name\",\n                                info=\"Name of the new collection to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"embedding_generation_provider\": DropdownInput(\n                                name=\"embedding_generation_provider\",\n                                display_name=\"Embedding Generation Provider\",\n                                info=\"Provider to use for generating embeddings.\",\n                                options=[],\n                                required=True,\n                            ),\n                            \"embedding_generation_model\": DropdownInput(\n                                name=\"embedding_generation_model\",\n                                display_name=\"Embedding Generation Model\",\n                                info=\"Model to use for generating embeddings.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        StrInput(\n            name=\"environment\",\n            display_name=\"Environment\",\n            info=\"The environment for the Astra DB API Endpoint.\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\",\n            info=\"The Database / API Endpoint for the Astra DB instance.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            combobox=True,\n        ),\n        StrInput(\n            name=\"d_api_endpoint\",\n            display_name=\"Database API Endpoint\",\n            info=\"The API Endpoint for the Astra DB instance. Supercedes database selection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"collection_name\",\n            display_name=\"Collection\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            # dialog_inputs=asdict(NewCollectionInput()),\n            combobox=True,\n        ),\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"embedding_choice\",\n            display_name=\"Embedding Model or Astra Vectorize\",\n            info=\"Choose an embedding model or use Astra Vectorize.\",\n            options=[\"Embedding Model\", \"Astra Vectorize\"],\n            value=\"Embedding Model\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n        ),\n        *LCVectorStoreComponent.inputs,\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Search Results\",\n            info=\"Number of search results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"advanced_search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autodetect_collection\",\n            display_name=\"Autodetect Collection\",\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\n            advanced=True,\n            value=True,\n        ),\n        StrInput(\n            name=\"content_field\",\n            display_name=\"Content Field\",\n            info=\"Field to use as the text content field for the vector store.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"deletion_field\",\n            display_name=\"Deletion Based On Field\",\n            info=\"When this parameter is provided, documents in the target collection with \"\n            \"metadata field values matching the input metadata field value will be deleted \"\n            \"before new data is loaded.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"ignore_invalid_documents\",\n            display_name=\"Ignore Invalid Documents\",\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"astradb_vectorstore_kwargs\",\n            display_name=\"AstraDBVectorStore Parameters\",\n            info=\"Optional dictionary of additional parameters for the AstraDBVectorStore.\",\n            advanced=True,\n        ),\n    ]\n\n    @classmethod\n    def map_cloud_providers(cls):\n        return {\n            \"Amazon Web Services\": {\n                \"id\": \"aws\",\n                \"regions\": [\"us-east-2\", \"ap-south-1\", \"eu-west-1\"],\n            },\n            \"Google Cloud Platform\": {\n                \"id\": \"gcp\",\n                \"regions\": [\"us-east1\"],\n            },\n            \"Microsoft Azure\": {\n                \"id\": \"azure\",\n                \"regions\": [\"westus3\"],\n            },\n        }\n\n    @classmethod\n    def create_database_api(\n        cls,\n        token: str,\n        new_database_name: str,\n        cloud_provider: str,\n        region: str,\n    ):\n        client = DataAPIClient(token=token)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Call the create database function\n        return admin_client.create_database(\n            name=new_database_name,\n            cloud_provider=cloud_provider,\n            region=region,\n        )\n\n    @classmethod\n    def create_collection_api(\n        cls,\n        token: str,\n        database_name: str,\n        new_collection_name: str,\n        dimension: int | None = None,\n        embedding_generation_provider: str | None = None,\n        embedding_generation_model: str | None = None,\n    ):\n        client = DataAPIClient(token=token)\n        api_endpoint = cls.get_api_endpoint_static(token=token, database_name=database_name)\n\n        # Get the database object\n        database = client.get_database(api_endpoint=api_endpoint, token=token)\n\n        # Build vectorize options, if needed\n        vectorize_options = None\n        if not dimension:\n            vectorize_options = CollectionVectorServiceOptions(\n                provider=embedding_generation_provider,\n                model_name=embedding_generation_model,\n                authentication=None,\n                parameters=None,\n            )\n\n        # Create the collection\n        return database.create_collection(\n            name=new_collection_name,\n            dimension=dimension,\n            service=vectorize_options,\n        )\n\n    @classmethod\n    def get_database_list_static(cls, token: str, environment: str | None = None):\n        client = DataAPIClient(token=token, environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the list of databases\n        db_list = list(admin_client.list_databases())\n\n        # Set the environment properly\n        env_string = \"\"\n        if environment and environment != \"prod\":\n            env_string = f\"-{environment}\"\n\n        # Generate the api endpoint for each database\n        db_info_dict = {}\n        for db in db_list:\n            try:\n                api_endpoint = f\"https://{db.info.id}-{db.info.region}.apps.astra{env_string}.datastax.com\"\n                db_info_dict[db.info.name] = {\n                    \"api_endpoint\": api_endpoint,\n                    \"collections\": len(\n                        list(\n                            client.get_database(\n                                api_endpoint=api_endpoint, token=token, keyspace=db.info.keyspace\n                            ).list_collection_names(keyspace=db.info.keyspace)\n                        )\n                    ),\n                }\n            except Exception:  # noqa: BLE001, S110\n                pass\n\n        return db_info_dict\n\n    def get_database_list(self):\n        return self.get_database_list_static(token=self.token, environment=self.environment)\n\n    @classmethod\n    def get_api_endpoint_static(\n        cls,\n        token: str,\n        environment: str | None = None,\n        api_endpoint: str | None = None,\n        database_name: str | None = None,\n    ):\n        # If the api_endpoint is set, return it\n        if api_endpoint:\n            return api_endpoint\n\n        # Check if the database_name is like a url\n        if database_name and database_name.startswith(\"https://\"):\n            return database_name\n\n        # If the database is not set, nothing we can do.\n        if not database_name:\n            return None\n\n        # Otherwise, get the URL from the database list\n        return cls.get_database_list_static(token=token, environment=environment).get(database_name).get(\"api_endpoint\")\n\n    def get_api_endpoint(self, *, api_endpoint: str | None = None):\n        return self.get_api_endpoint_static(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=api_endpoint or self.d_api_endpoint,\n            database_name=self.api_endpoint,\n        )\n\n    def get_keyspace(self):\n        keyspace = self.keyspace\n\n        if keyspace:\n            return keyspace.strip()\n\n        return None\n\n    def get_database_object(self, api_endpoint: str | None = None):\n        try:\n            client = DataAPIClient(token=self.token, environment=self.environment)\n\n            return client.get_database(\n                api_endpoint=self.get_api_endpoint(api_endpoint=api_endpoint),\n                token=self.token,\n                keyspace=self.get_keyspace(),\n            )\n        except Exception as e:\n            msg = f\"Error fetching database object: {e}\"\n            raise ValueError(msg) from e\n\n    def collection_data(self, collection_name: str, database: Database | None = None):\n        try:\n            if not database:\n                client = DataAPIClient(token=self.token, environment=self.environment)\n\n                database = client.get_database(\n                    api_endpoint=self.get_api_endpoint(),\n                    token=self.token,\n                    keyspace=self.get_keyspace(),\n                )\n\n            collection = database.get_collection(collection_name, keyspace=self.get_keyspace())\n\n            return collection.estimated_document_count()\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error checking collection data: {e}\")\n\n            return None\n\n    def get_vectorize_providers(self):\n        try:\n            self.log(\"Dynamically updating list of Vectorize providers.\")\n\n            # Get the admin object\n            admin = AstraDBAdmin(token=self.token)\n            db_admin = admin.get_database_admin(api_endpoint=self.get_api_endpoint())\n\n            # Get the list of embedding providers\n            embedding_providers = db_admin.find_embedding_providers().as_dict()\n\n            vectorize_providers_mapping = {}\n            # Map the provider display name to the provider key and models\n            for provider_key, provider_data in embedding_providers[\"embeddingProviders\"].items():\n                display_name = provider_data[\"displayName\"]\n                models = [model[\"name\"] for model in provider_data[\"models\"]]\n\n                # TODO: https://astra.datastax.com/api/v2/graphql\n                vectorize_providers_mapping[display_name] = [provider_key, models]\n\n            # Sort the resulting dictionary\n            return defaultdict(list, dict(sorted(vectorize_providers_mapping.items())))\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error fetching Vectorize providers: {e}\")\n\n            return {}\n\n    def _initialize_database_options(self):\n        try:\n            return [\n                {\n                    \"name\": name,\n                    \"collections\": info[\"collections\"],\n                    \"api_endpoint\": info[\"api_endpoint\"],\n                }\n                for name, info in self.get_database_list().items()\n            ]\n        except Exception as e:\n            msg = f\"Error fetching database options: {e}\"\n            raise ValueError(msg) from e\n\n    def _initialize_collection_options(self, api_endpoint: str | None = None):\n        # Retrieve the database object\n        database = self.get_database_object(api_endpoint=api_endpoint)\n\n        # Get the list of collections\n        collection_list = list(database.list_collections(keyspace=self.get_keyspace()))\n\n        # Return the list of collections and metadata associated\n        return [\n            {\n                \"name\": col.name,\n                \"records\": self.collection_data(collection_name=col.name, database=database),\n                \"provider\": (\n                    col.options.vector.service.provider if col.options.vector and col.options.vector.service else None\n                ),\n                \"icon\": \"\",\n                \"model\": (\n                    col.options.vector.service.model_name if col.options.vector and col.options.vector.service else None\n                ),\n            }\n            for col in collection_list\n        ]\n\n    def reset_collection_list(self, build_config: dict):\n        # Get the list of options we have based on the token provided\n        collection_options = self._initialize_collection_options()\n\n        # If we retrieved options based on the token, show the dropdown\n        build_config[\"collection_name\"][\"options\"] = [col[\"name\"] for col in collection_options]\n        build_config[\"collection_name\"][\"options_metadata\"] = [\n            {k: v for k, v in col.items() if k not in [\"name\"]} for col in collection_options\n        ]\n\n        # Reset the selected collection\n        build_config[\"collection_name\"][\"value\"] = \"\"\n\n        return build_config\n\n    def reset_database_list(self, build_config: dict):\n        # Get the list of options we have based on the token provided\n        database_options = self._initialize_database_options()\n\n        # If we retrieved options based on the token, show the dropdown\n        build_config[\"api_endpoint\"][\"options\"] = [db[\"name\"] for db in database_options]\n        build_config[\"api_endpoint\"][\"options_metadata\"] = [\n            {k: v for k, v in db.items() if k not in [\"name\"]} for db in database_options\n        ]\n\n        # Reset the selected database\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n\n        return build_config\n\n    def reset_build_config(self, build_config: dict):\n        # Reset the list of databases we have based on the token provided\n        build_config[\"api_endpoint\"][\"options\"] = []\n        build_config[\"api_endpoint\"][\"options_metadata\"] = []\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n        build_config[\"api_endpoint\"][\"name\"] = \"Database\"\n\n        # Reset the list of collections and metadata associated\n        build_config[\"collection_name\"][\"options\"] = []\n        build_config[\"collection_name\"][\"options_metadata\"] = []\n        build_config[\"collection_name\"][\"value\"] = \"\"\n\n        return build_config\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        # When the component first executes, this is the update refresh call\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"api_endpoint\"][\"options\"]\n\n        # If the token has not been provided, simply return\n        if not self.token:\n            return self.reset_build_config(build_config)\n\n        # If this is the first execution of the component, reset and build database list\n        if first_run or field_name in [\"token\", \"environment\"]:\n            # Reset the build config to ensure we are starting fresh\n            build_config = self.reset_build_config(build_config)\n            build_config = self.reset_database_list(build_config)\n\n            # Get list of regions for a given cloud provider\n            \"\"\"\n            cloud_provider = (\n                build_config[\"api_endpoint\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\"cloud_provider\"][\n                    \"value\"\n                ]\n                or \"Amazon Web Services\"\n            )\n            build_config[\"api_endpoint\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\"region\"][\n                \"options\"\n            ] = self.map_cloud_providers()[cloud_provider][\"regions\"]\n            \"\"\"\n\n            return build_config\n\n        # Refresh the collection name options\n        if field_name == \"api_endpoint\":\n            # If missing, refresh the database options\n            if not build_config[\"api_endpoint\"][\"options\"] or not field_value:\n                return self.update_build_config(build_config, field_value=self.token, field_name=\"token\")\n\n            # Set the underlying api endpoint value of the database\n            if field_value in build_config[\"api_endpoint\"][\"options\"]:\n                index_of_name = build_config[\"api_endpoint\"][\"options\"].index(field_value)\n                build_config[\"d_api_endpoint\"][\"value\"] = build_config[\"api_endpoint\"][\"options_metadata\"][\n                    index_of_name\n                ][\"api_endpoint\"]\n            else:\n                build_config[\"d_api_endpoint\"][\"value\"] = \"\"\n\n            # Reset the list of collections we have based on the token provided\n            return self.reset_collection_list(build_config)\n\n        # Hide embedding model option if opriona_metadata provider is not null\n        if field_name == \"collection_name\" and field_value:\n            # Assume we will be autodetecting the collection:\n            build_config[\"autodetect_collection\"][\"value\"] = True\n\n            # Set the options for collection name to be the field value if its a new collection\n            if field_value not in build_config[\"collection_name\"][\"options\"]:\n                # Add the new collection to the list of options\n                build_config[\"collection_name\"][\"options\"].append(field_value)\n                build_config[\"collection_name\"][\"options_metadata\"].append(\n                    {\"records\": 0, \"provider\": None, \"icon\": \"\", \"model\": None}\n                )\n\n                # Ensure that autodetect collection is set to False, since its a new collection\n                build_config[\"autodetect_collection\"][\"value\"] = False\n\n            # Find the position of the selected collection to align with metadata\n            index_of_name = build_config[\"collection_name\"][\"options\"].index(field_value)\n            value_of_provider = build_config[\"collection_name\"][\"options_metadata\"][index_of_name][\"provider\"]\n\n            # If we were able to determine the Vectorize provider, set it accordingly\n            if value_of_provider:\n                build_config[\"embedding_model\"][\"advanced\"] = True\n                build_config[\"embedding_choice\"][\"value\"] = \"Astra Vectorize\"\n            else:\n                build_config[\"embedding_model\"][\"advanced\"] = False\n                build_config[\"embedding_choice\"][\"value\"] = \"Embedding Model\"\n\n        # For the final step, get the list of vectorize providers\n        \"\"\"\n        vectorize_providers = self.get_vectorize_providers()\n        if not vectorize_providers:\n            return build_config\n\n        # Allow the user to see the embedding provider options\n        provider_options = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_provider\"\n        ][\"options\"]\n        if not provider_options:\n            # If the collection is set, allow user to see embedding options\n            build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_provider\"\n            ][\"options\"] = [\"Bring your own\", \"Nvidia\", *[key for key in vectorize_providers if key != \"Nvidia\"]]\n\n        # And allow the user to see the models based on a selected provider\n        model_options = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_model\"\n        ][\"options\"]\n        if not model_options:\n            embedding_provider = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_provider\"\n            ][\"value\"]\n\n            build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_model\"\n            ][\"options\"] = vectorize_providers.get(embedding_provider, [[], []])[1]\n        \"\"\"\n\n        return build_config\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        # Get the embedding model and additional params\n        embedding_params = (\n            {\"embedding\": self.embedding_model}\n            if self.embedding_model and self.embedding_choice == \"Embedding Model\"\n            else {}\n        )\n\n        # Get the additional parameters\n        additional_params = self.astradb_vectorstore_kwargs or {}\n\n        # Get Langflow version and platform information\n        __version__ = get_version_info()[\"version\"]\n        langflow_prefix = \"\"\n        if os.getenv(\"AWS_EXECUTION_ENV\") == \"AWS_ECS_FARGATE\":  # TODO: More precise way of detecting\n            langflow_prefix = \"ds-\"\n\n        # Get the database object\n        database = self.get_database_object(api_endpoint=self.d_api_endpoint)\n        autodetect = self.collection_name in database.list_collection_names() and self.autodetect_collection\n\n        # Bundle up the auto-detect parameters\n        autodetect_params = {\n            \"autodetect_collection\": autodetect,\n            \"content_field\": (\n                self.content_field\n                if self.content_field and embedding_params\n                else (\n                    \"page_content\"\n                    if embedding_params\n                    and self.collection_data(collection_name=self.collection_name, database=database) == 0\n                    else None\n                )\n            ),\n            \"ignore_invalid_documents\": self.ignore_invalid_documents,\n        }\n\n        # Attempt to build the Vector Store object\n        try:\n            vector_store = AstraDBVectorStore(\n                # Astra DB Authentication Parameters\n                token=self.token,\n                api_endpoint=database.api_endpoint,\n                namespace=database.keyspace,\n                collection_name=self.collection_name,\n                environment=self.environment,\n                # Astra DB Usage Tracking Parameters\n                ext_callers=[(f\"{langflow_prefix}langflow\", __version__)],\n                # Astra DB Vector Store Parameters\n                **autodetect_params,\n                **embedding_params,\n                **additional_params,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        # Add documents to the vector store\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents and self.deletion_field:\n            self.log(f\"Deleting documents where {self.deletion_field}\")\n            try:\n                database = self.get_database_object(api_endpoint=self.d_api_endpoint)\n                collection = database.get_collection(self.collection_name, keyspace=database.keyspace)\n                delete_values = list({doc.metadata[self.deletion_field] for doc in documents})\n                self.log(f\"Deleting documents where {self.deletion_field} matches {delete_values}.\")\n                collection.delete_many({f\"metadata.{self.deletion_field}\": {\"$in\": delete_values}})\n            except Exception as e:\n                msg = f\"Error deleting documents from AstraDBVectorStore based on '{self.deletion_field}': {e}\"\n                raise ValueError(msg) from e\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        search_type_mapping = {\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\n        }\n\n        return search_type_mapping.get(self.search_type, \"similarity\")\n\n    def _build_search_args(self):\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\n\n        if query:\n            args = {\n                \"query\": query,\n                \"search_type\": self._map_search_type(),\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n            }\n        elif self.advanced_search_filter:\n            args = {\n                \"n\": self.number_of_results,\n            }\n        else:\n            return {}\n\n        filter_arg = self.advanced_search_filter or {}\n        if filter_arg:\n            args[\"filter\"] = filter_arg\n\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        vector_store = vector_store or self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        try:\n            search_args = self._build_search_args()\n        except Exception as e:\n            msg = f\"Error in AstraDBVectorStore._build_search_args: {e}\"\n            raise ValueError(msg) from e\n\n        if not search_args:\n            self.log(\"No search input or filters provided. Skipping search.\")\n            return []\n\n        docs = []\n        search_method = \"search\" if \"query\" in search_args else \"metadata_search\"\n\n        try:\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\n            docs = getattr(vector_store, search_method)(**search_args)\n        except Exception as e:\n            msg = f\"Error performing {search_method} in AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Retrieved documents: {len(docs)}\")\n\n        data = docs_to_data(docs)\n        self.log(f\"Converted documents to data: {len(data)}\")\n        self.status = data\n\n        return data\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "dishesinfo_1"
                ],
                "options_metadata": [
                  {
                    "records": 0,
                    "provider": null,
                    "icon": "",
                    "model": null
                  }
                ],
                "combobox": true,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "dishesinfo_1",
                "display_name": "Collection",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "content_field": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "content_field",
                "value": "",
                "display_name": "Content Field",
                "advanced": true,
                "dynamic": false,
                "info": "Field to use as the text content field for the vector store.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "d_api_endpoint": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "d_api_endpoint",
                "value": "",
                "display_name": "Database API Endpoint",
                "advanced": true,
                "dynamic": false,
                "info": "The API Endpoint for the Astra DB instance. Supercedes database selection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "deletion_field": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deletion_field",
                "value": "",
                "display_name": "Deletion Based On Field",
                "advanced": true,
                "dynamic": false,
                "info": "When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "embedding_choice": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Embedding Model",
                  "Astra Vectorize"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_choice",
                "value": "Embedding Model",
                "display_name": "Embedding Model or Astra Vectorize",
                "advanced": true,
                "dynamic": false,
                "info": "Choose an embedding model or use Astra Vectorize.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "environment": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "environment",
                "value": "",
                "display_name": "Environment",
                "advanced": true,
                "dynamic": false,
                "info": "The environment for the Astra DB API Endpoint.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "ignore_invalid_documents": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ignore_invalid_documents",
                "value": false,
                "display_name": "Ignore Invalid Documents",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to ignore invalid documents at runtime.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "keyspace": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "keyspace",
                "value": "",
                "display_name": "Keyspace",
                "advanced": true,
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Search Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of search results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_query": {
                "tool_mode": true,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "search_score_threshold": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_score_threshold",
                "value": 0,
                "display_name": "Search Score Threshold",
                "advanced": true,
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "search_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_type",
                "value": "Similarity",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "Search type to use",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "token": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "token",
                "value": "",
                "display_name": "Astra DB Application Token",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "real_time_refresh": true,
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Ingest and search documents in Astra DB",
            "icon": "AstraDB",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "Astra DB",
            "documentation": "https://docs.datastax.com/en/langflow/astra-components.html",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "hidden": null,
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "hidden": null,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "token",
              "environment",
              "api_endpoint",
              "d_api_endpoint",
              "collection_name",
              "keyspace",
              "embedding_choice",
              "embedding_model",
              "ingest_data",
              "search_query",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "advanced_search_filter",
              "autodetect_collection",
              "content_field",
              "deletion_field",
              "ignore_invalid_documents",
              "astradb_vectorstore_kwargs"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "vectorstores",
            "key": "AstraDB",
            "score": 0.007568328950209746,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "AstraDB",
          "id": "AstraDB-4xL8y"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 621
        },
        "dragging": false
      },
      {
        "id": "NVIDIAEmbeddingsComponent-LEv6l",
        "type": "genericNode",
        "position": {
          "x": -846.1343645596658,
          "y": 735.8446027086659
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "base_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "https://integrate.api.nvidia.com/v1",
                "display_name": "NVIDIA Base URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.field_typing import Embeddings\nfrom langflow.inputs.inputs import DropdownInput, SecretStrInput\nfrom langflow.io import FloatInput, MessageTextInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass NVIDIAEmbeddingsComponent(LCEmbeddingsModel):\n    display_name: str = \"NVIDIA Embeddings\"\n    description: str = \"Generate embeddings using NVIDIA models.\"\n    icon = \"NVIDIA\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"nvidia/nv-embed-v1\",\n                \"snowflake/arctic-embed-I\",\n            ],\n            value=\"nvidia/nv-embed-v1\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"NVIDIA Base URL\",\n            refresh_button=True,\n            value=\"https://integrate.api.nvidia.com/v1\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"nvidia_api_key\",\n            display_name=\"NVIDIA API Key\",\n            info=\"The NVIDIA API Key.\",\n            advanced=False,\n            value=\"NVIDIA_API_KEY\",\n            required=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"base_url\" and field_value:\n            try:\n                build_model = self.build_embeddings()\n                ids = [model.id for model in build_model.available_models]\n                build_config[\"model\"][\"options\"] = ids\n                build_config[\"model\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the Nvidia model.\"\n            raise ImportError(msg) from e\n        try:\n            output = NVIDIAEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n                nvidia_api_key=self.nvidia_api_key,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to NVIDIA API. Error: {e}\"\n            raise ValueError(msg) from e\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "nvidia/nv-embedqa-mistral-7b-v2",
                  "nvidia/nv-embed-v1",
                  "baai/bge-m3",
                  "NV-Embed-QA",
                  "nvidia/embed-qa-4",
                  "nvidia/nv-embedqa-e5-v5",
                  "nvidia/llama-3.2-nv-embedqa-1b-v1",
                  "snowflake/arctic-embed-l"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "baai/bge-m3",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "nvidia_api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "nvidia_api_key",
                "value": "",
                "display_name": "NVIDIA API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The NVIDIA API Key.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "temperature": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Model Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate embeddings using NVIDIA models.",
            "icon": "NVIDIA",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "NVIDIA Embeddings",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "hidden": null,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "base_url",
                  "model",
                  "nvidia_api_key"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "model",
              "base_url",
              "nvidia_api_key",
              "temperature"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "embeddings",
            "key": "NVIDIAEmbeddingsComponent",
            "score": 0.000052003277518821525,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "NVIDIAEmbeddingsComponent",
          "id": "NVIDIAEmbeddingsComponent-LEv6l"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 399
        },
        "dragging": false
      },
      {
        "id": "AstraDB-5I9kj",
        "type": "genericNode",
        "position": {
          "x": -432.594887706476,
          "y": 579.5550839923638
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "embedding_model": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_model",
                "value": "",
                "display_name": "Embedding Model",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Specify the Embedding Model. Not required for Astra Vectorize collections.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "advanced_search_filter": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "advanced_search_filter",
                "value": {},
                "display_name": "Search Metadata Filter",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "api_endpoint": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [],
                "options_metadata": [],
                "combobox": true,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_endpoint",
                "value": "https://3c2b3c61-1161-40c2-b703-d22eaa69b8e5-us-east-2.apps.astra.datastax.com",
                "display_name": "Database",
                "advanced": false,
                "dynamic": false,
                "info": "The Database / API Endpoint for the Astra DB instance.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "astradb_vectorstore_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "astradb_vectorstore_kwargs",
                "value": {},
                "display_name": "AstraDBVectorStore Parameters",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of additional parameters for the AstraDBVectorStore.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "autodetect_collection": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "autodetect_collection",
                "value": true,
                "display_name": "Autodetect Collection",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to autodetect the collection.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\n\nfrom astrapy import AstraDBAdmin, DataAPIClient, Database\nfrom langchain_astradb import AstraDBVectorStore, CollectionVectorServiceOptions\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import FloatInput, NestedDictInput\nfrom langflow.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\nfrom langflow.utils.version import get_version_info\n\n\nclass AstraDBVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Ingest and search documents in Astra DB\"\n    documentation: str = \"https://docs.datastax.com/en/langflow/astra-components.html\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vector_store: AstraDBVectorStore | None = None\n\n    @dataclass\n    class NewDatabaseInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"description\": \"Create a new database in Astra DB.\",\n                        \"display_name\": \"Create New Database\",\n                        \"field_order\": [\"new_database_name\", \"cloud_provider\", \"region\"],\n                        \"template\": {\n                            \"new_database_name\": StrInput(\n                                name=\"new_database_name\",\n                                display_name=\"New Database Name\",\n                                info=\"Name of the new database to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"cloud_provider\": DropdownInput(\n                                name=\"cloud_provider\",\n                                display_name=\"Cloud Provider\",\n                                info=\"Cloud provider for the new database.\",\n                                options=[\"Amazon Web Services\", \"Google Cloud Platform\", \"Microsoft Azure\"],\n                                required=True,\n                            ),\n                            \"region\": DropdownInput(\n                                name=\"region\",\n                                display_name=\"Region\",\n                                info=\"Region for the new database.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    @dataclass\n    class NewCollectionInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"description\": \"Create a new collection in Astra DB.\",\n                        \"display_name\": \"Create New Collection\",\n                        \"field_order\": [\n                            \"new_collection_name\",\n                            \"embedding_generation_provider\",\n                            \"embedding_generation_model\",\n                        ],\n                        \"template\": {\n                            \"new_collection_name\": StrInput(\n                                name=\"new_collection_name\",\n                                display_name=\"New Collection Name\",\n                                info=\"Name of the new collection to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"embedding_generation_provider\": DropdownInput(\n                                name=\"embedding_generation_provider\",\n                                display_name=\"Embedding Generation Provider\",\n                                info=\"Provider to use for generating embeddings.\",\n                                options=[],\n                                required=True,\n                            ),\n                            \"embedding_generation_model\": DropdownInput(\n                                name=\"embedding_generation_model\",\n                                display_name=\"Embedding Generation Model\",\n                                info=\"Model to use for generating embeddings.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        StrInput(\n            name=\"environment\",\n            display_name=\"Environment\",\n            info=\"The environment for the Astra DB API Endpoint.\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\",\n            info=\"The Database / API Endpoint for the Astra DB instance.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            combobox=True,\n        ),\n        StrInput(\n            name=\"d_api_endpoint\",\n            display_name=\"Database API Endpoint\",\n            info=\"The API Endpoint for the Astra DB instance. Supercedes database selection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"collection_name\",\n            display_name=\"Collection\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            # dialog_inputs=asdict(NewCollectionInput()),\n            combobox=True,\n        ),\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"embedding_choice\",\n            display_name=\"Embedding Model or Astra Vectorize\",\n            info=\"Choose an embedding model or use Astra Vectorize.\",\n            options=[\"Embedding Model\", \"Astra Vectorize\"],\n            value=\"Embedding Model\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n        ),\n        *LCVectorStoreComponent.inputs,\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Search Results\",\n            info=\"Number of search results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"advanced_search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autodetect_collection\",\n            display_name=\"Autodetect Collection\",\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\n            advanced=True,\n            value=True,\n        ),\n        StrInput(\n            name=\"content_field\",\n            display_name=\"Content Field\",\n            info=\"Field to use as the text content field for the vector store.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"deletion_field\",\n            display_name=\"Deletion Based On Field\",\n            info=\"When this parameter is provided, documents in the target collection with \"\n            \"metadata field values matching the input metadata field value will be deleted \"\n            \"before new data is loaded.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"ignore_invalid_documents\",\n            display_name=\"Ignore Invalid Documents\",\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"astradb_vectorstore_kwargs\",\n            display_name=\"AstraDBVectorStore Parameters\",\n            info=\"Optional dictionary of additional parameters for the AstraDBVectorStore.\",\n            advanced=True,\n        ),\n    ]\n\n    @classmethod\n    def map_cloud_providers(cls):\n        return {\n            \"Amazon Web Services\": {\n                \"id\": \"aws\",\n                \"regions\": [\"us-east-2\", \"ap-south-1\", \"eu-west-1\"],\n            },\n            \"Google Cloud Platform\": {\n                \"id\": \"gcp\",\n                \"regions\": [\"us-east1\"],\n            },\n            \"Microsoft Azure\": {\n                \"id\": \"azure\",\n                \"regions\": [\"westus3\"],\n            },\n        }\n\n    @classmethod\n    def create_database_api(\n        cls,\n        token: str,\n        new_database_name: str,\n        cloud_provider: str,\n        region: str,\n    ):\n        client = DataAPIClient(token=token)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Call the create database function\n        return admin_client.create_database(\n            name=new_database_name,\n            cloud_provider=cloud_provider,\n            region=region,\n        )\n\n    @classmethod\n    def create_collection_api(\n        cls,\n        token: str,\n        database_name: str,\n        new_collection_name: str,\n        dimension: int | None = None,\n        embedding_generation_provider: str | None = None,\n        embedding_generation_model: str | None = None,\n    ):\n        client = DataAPIClient(token=token)\n        api_endpoint = cls.get_api_endpoint_static(token=token, database_name=database_name)\n\n        # Get the database object\n        database = client.get_database(api_endpoint=api_endpoint, token=token)\n\n        # Build vectorize options, if needed\n        vectorize_options = None\n        if not dimension:\n            vectorize_options = CollectionVectorServiceOptions(\n                provider=embedding_generation_provider,\n                model_name=embedding_generation_model,\n                authentication=None,\n                parameters=None,\n            )\n\n        # Create the collection\n        return database.create_collection(\n            name=new_collection_name,\n            dimension=dimension,\n            service=vectorize_options,\n        )\n\n    @classmethod\n    def get_database_list_static(cls, token: str, environment: str | None = None):\n        client = DataAPIClient(token=token, environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the list of databases\n        db_list = list(admin_client.list_databases())\n\n        # Set the environment properly\n        env_string = \"\"\n        if environment and environment != \"prod\":\n            env_string = f\"-{environment}\"\n\n        # Generate the api endpoint for each database\n        db_info_dict = {}\n        for db in db_list:\n            try:\n                api_endpoint = f\"https://{db.info.id}-{db.info.region}.apps.astra{env_string}.datastax.com\"\n                db_info_dict[db.info.name] = {\n                    \"api_endpoint\": api_endpoint,\n                    \"collections\": len(\n                        list(\n                            client.get_database(\n                                api_endpoint=api_endpoint, token=token, keyspace=db.info.keyspace\n                            ).list_collection_names(keyspace=db.info.keyspace)\n                        )\n                    ),\n                }\n            except Exception:  # noqa: BLE001, S110\n                pass\n\n        return db_info_dict\n\n    def get_database_list(self):\n        return self.get_database_list_static(token=self.token, environment=self.environment)\n\n    @classmethod\n    def get_api_endpoint_static(\n        cls,\n        token: str,\n        environment: str | None = None,\n        api_endpoint: str | None = None,\n        database_name: str | None = None,\n    ):\n        # If the api_endpoint is set, return it\n        if api_endpoint:\n            return api_endpoint\n\n        # Check if the database_name is like a url\n        if database_name and database_name.startswith(\"https://\"):\n            return database_name\n\n        # If the database is not set, nothing we can do.\n        if not database_name:\n            return None\n\n        # Otherwise, get the URL from the database list\n        return cls.get_database_list_static(token=token, environment=environment).get(database_name).get(\"api_endpoint\")\n\n    def get_api_endpoint(self, *, api_endpoint: str | None = None):\n        return self.get_api_endpoint_static(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=api_endpoint or self.d_api_endpoint,\n            database_name=self.api_endpoint,\n        )\n\n    def get_keyspace(self):\n        keyspace = self.keyspace\n\n        if keyspace:\n            return keyspace.strip()\n\n        return None\n\n    def get_database_object(self, api_endpoint: str | None = None):\n        try:\n            client = DataAPIClient(token=self.token, environment=self.environment)\n\n            return client.get_database(\n                api_endpoint=self.get_api_endpoint(api_endpoint=api_endpoint),\n                token=self.token,\n                keyspace=self.get_keyspace(),\n            )\n        except Exception as e:\n            msg = f\"Error fetching database object: {e}\"\n            raise ValueError(msg) from e\n\n    def collection_data(self, collection_name: str, database: Database | None = None):\n        try:\n            if not database:\n                client = DataAPIClient(token=self.token, environment=self.environment)\n\n                database = client.get_database(\n                    api_endpoint=self.get_api_endpoint(),\n                    token=self.token,\n                    keyspace=self.get_keyspace(),\n                )\n\n            collection = database.get_collection(collection_name, keyspace=self.get_keyspace())\n\n            return collection.estimated_document_count()\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error checking collection data: {e}\")\n\n            return None\n\n    def get_vectorize_providers(self):\n        try:\n            self.log(\"Dynamically updating list of Vectorize providers.\")\n\n            # Get the admin object\n            admin = AstraDBAdmin(token=self.token)\n            db_admin = admin.get_database_admin(api_endpoint=self.get_api_endpoint())\n\n            # Get the list of embedding providers\n            embedding_providers = db_admin.find_embedding_providers().as_dict()\n\n            vectorize_providers_mapping = {}\n            # Map the provider display name to the provider key and models\n            for provider_key, provider_data in embedding_providers[\"embeddingProviders\"].items():\n                display_name = provider_data[\"displayName\"]\n                models = [model[\"name\"] for model in provider_data[\"models\"]]\n\n                # TODO: https://astra.datastax.com/api/v2/graphql\n                vectorize_providers_mapping[display_name] = [provider_key, models]\n\n            # Sort the resulting dictionary\n            return defaultdict(list, dict(sorted(vectorize_providers_mapping.items())))\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error fetching Vectorize providers: {e}\")\n\n            return {}\n\n    def _initialize_database_options(self):\n        try:\n            return [\n                {\n                    \"name\": name,\n                    \"collections\": info[\"collections\"],\n                    \"api_endpoint\": info[\"api_endpoint\"],\n                }\n                for name, info in self.get_database_list().items()\n            ]\n        except Exception as e:\n            msg = f\"Error fetching database options: {e}\"\n            raise ValueError(msg) from e\n\n    def _initialize_collection_options(self, api_endpoint: str | None = None):\n        # Retrieve the database object\n        database = self.get_database_object(api_endpoint=api_endpoint)\n\n        # Get the list of collections\n        collection_list = list(database.list_collections(keyspace=self.get_keyspace()))\n\n        # Return the list of collections and metadata associated\n        return [\n            {\n                \"name\": col.name,\n                \"records\": self.collection_data(collection_name=col.name, database=database),\n                \"provider\": (\n                    col.options.vector.service.provider if col.options.vector and col.options.vector.service else None\n                ),\n                \"icon\": \"\",\n                \"model\": (\n                    col.options.vector.service.model_name if col.options.vector and col.options.vector.service else None\n                ),\n            }\n            for col in collection_list\n        ]\n\n    def reset_collection_list(self, build_config: dict):\n        # Get the list of options we have based on the token provided\n        collection_options = self._initialize_collection_options()\n\n        # If we retrieved options based on the token, show the dropdown\n        build_config[\"collection_name\"][\"options\"] = [col[\"name\"] for col in collection_options]\n        build_config[\"collection_name\"][\"options_metadata\"] = [\n            {k: v for k, v in col.items() if k not in [\"name\"]} for col in collection_options\n        ]\n\n        # Reset the selected collection\n        build_config[\"collection_name\"][\"value\"] = \"\"\n\n        return build_config\n\n    def reset_database_list(self, build_config: dict):\n        # Get the list of options we have based on the token provided\n        database_options = self._initialize_database_options()\n\n        # If we retrieved options based on the token, show the dropdown\n        build_config[\"api_endpoint\"][\"options\"] = [db[\"name\"] for db in database_options]\n        build_config[\"api_endpoint\"][\"options_metadata\"] = [\n            {k: v for k, v in db.items() if k not in [\"name\"]} for db in database_options\n        ]\n\n        # Reset the selected database\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n\n        return build_config\n\n    def reset_build_config(self, build_config: dict):\n        # Reset the list of databases we have based on the token provided\n        build_config[\"api_endpoint\"][\"options\"] = []\n        build_config[\"api_endpoint\"][\"options_metadata\"] = []\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n        build_config[\"api_endpoint\"][\"name\"] = \"Database\"\n\n        # Reset the list of collections and metadata associated\n        build_config[\"collection_name\"][\"options\"] = []\n        build_config[\"collection_name\"][\"options_metadata\"] = []\n        build_config[\"collection_name\"][\"value\"] = \"\"\n\n        return build_config\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        # When the component first executes, this is the update refresh call\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"api_endpoint\"][\"options\"]\n\n        # If the token has not been provided, simply return\n        if not self.token:\n            return self.reset_build_config(build_config)\n\n        # If this is the first execution of the component, reset and build database list\n        if first_run or field_name in [\"token\", \"environment\"]:\n            # Reset the build config to ensure we are starting fresh\n            build_config = self.reset_build_config(build_config)\n            build_config = self.reset_database_list(build_config)\n\n            # Get list of regions for a given cloud provider\n            \"\"\"\n            cloud_provider = (\n                build_config[\"api_endpoint\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\"cloud_provider\"][\n                    \"value\"\n                ]\n                or \"Amazon Web Services\"\n            )\n            build_config[\"api_endpoint\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\"region\"][\n                \"options\"\n            ] = self.map_cloud_providers()[cloud_provider][\"regions\"]\n            \"\"\"\n\n            return build_config\n\n        # Refresh the collection name options\n        if field_name == \"api_endpoint\":\n            # If missing, refresh the database options\n            if not build_config[\"api_endpoint\"][\"options\"] or not field_value:\n                return self.update_build_config(build_config, field_value=self.token, field_name=\"token\")\n\n            # Set the underlying api endpoint value of the database\n            if field_value in build_config[\"api_endpoint\"][\"options\"]:\n                index_of_name = build_config[\"api_endpoint\"][\"options\"].index(field_value)\n                build_config[\"d_api_endpoint\"][\"value\"] = build_config[\"api_endpoint\"][\"options_metadata\"][\n                    index_of_name\n                ][\"api_endpoint\"]\n            else:\n                build_config[\"d_api_endpoint\"][\"value\"] = \"\"\n\n            # Reset the list of collections we have based on the token provided\n            return self.reset_collection_list(build_config)\n\n        # Hide embedding model option if opriona_metadata provider is not null\n        if field_name == \"collection_name\" and field_value:\n            # Assume we will be autodetecting the collection:\n            build_config[\"autodetect_collection\"][\"value\"] = True\n\n            # Set the options for collection name to be the field value if its a new collection\n            if field_value not in build_config[\"collection_name\"][\"options\"]:\n                # Add the new collection to the list of options\n                build_config[\"collection_name\"][\"options\"].append(field_value)\n                build_config[\"collection_name\"][\"options_metadata\"].append(\n                    {\"records\": 0, \"provider\": None, \"icon\": \"\", \"model\": None}\n                )\n\n                # Ensure that autodetect collection is set to False, since its a new collection\n                build_config[\"autodetect_collection\"][\"value\"] = False\n\n            # Find the position of the selected collection to align with metadata\n            index_of_name = build_config[\"collection_name\"][\"options\"].index(field_value)\n            value_of_provider = build_config[\"collection_name\"][\"options_metadata\"][index_of_name][\"provider\"]\n\n            # If we were able to determine the Vectorize provider, set it accordingly\n            if value_of_provider:\n                build_config[\"embedding_model\"][\"advanced\"] = True\n                build_config[\"embedding_choice\"][\"value\"] = \"Astra Vectorize\"\n            else:\n                build_config[\"embedding_model\"][\"advanced\"] = False\n                build_config[\"embedding_choice\"][\"value\"] = \"Embedding Model\"\n\n        # For the final step, get the list of vectorize providers\n        \"\"\"\n        vectorize_providers = self.get_vectorize_providers()\n        if not vectorize_providers:\n            return build_config\n\n        # Allow the user to see the embedding provider options\n        provider_options = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_provider\"\n        ][\"options\"]\n        if not provider_options:\n            # If the collection is set, allow user to see embedding options\n            build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_provider\"\n            ][\"options\"] = [\"Bring your own\", \"Nvidia\", *[key for key in vectorize_providers if key != \"Nvidia\"]]\n\n        # And allow the user to see the models based on a selected provider\n        model_options = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_model\"\n        ][\"options\"]\n        if not model_options:\n            embedding_provider = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_provider\"\n            ][\"value\"]\n\n            build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_model\"\n            ][\"options\"] = vectorize_providers.get(embedding_provider, [[], []])[1]\n        \"\"\"\n\n        return build_config\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        # Get the embedding model and additional params\n        embedding_params = (\n            {\"embedding\": self.embedding_model}\n            if self.embedding_model and self.embedding_choice == \"Embedding Model\"\n            else {}\n        )\n\n        # Get the additional parameters\n        additional_params = self.astradb_vectorstore_kwargs or {}\n\n        # Get Langflow version and platform information\n        __version__ = get_version_info()[\"version\"]\n        langflow_prefix = \"\"\n        if os.getenv(\"AWS_EXECUTION_ENV\") == \"AWS_ECS_FARGATE\":  # TODO: More precise way of detecting\n            langflow_prefix = \"ds-\"\n\n        # Get the database object\n        database = self.get_database_object(api_endpoint=self.d_api_endpoint)\n        autodetect = self.collection_name in database.list_collection_names() and self.autodetect_collection\n\n        # Bundle up the auto-detect parameters\n        autodetect_params = {\n            \"autodetect_collection\": autodetect,\n            \"content_field\": (\n                self.content_field\n                if self.content_field and embedding_params\n                else (\n                    \"page_content\"\n                    if embedding_params\n                    and self.collection_data(collection_name=self.collection_name, database=database) == 0\n                    else None\n                )\n            ),\n            \"ignore_invalid_documents\": self.ignore_invalid_documents,\n        }\n\n        # Attempt to build the Vector Store object\n        try:\n            vector_store = AstraDBVectorStore(\n                # Astra DB Authentication Parameters\n                token=self.token,\n                api_endpoint=database.api_endpoint,\n                namespace=database.keyspace,\n                collection_name=self.collection_name,\n                environment=self.environment,\n                # Astra DB Usage Tracking Parameters\n                ext_callers=[(f\"{langflow_prefix}langflow\", __version__)],\n                # Astra DB Vector Store Parameters\n                **autodetect_params,\n                **embedding_params,\n                **additional_params,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        # Add documents to the vector store\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents and self.deletion_field:\n            self.log(f\"Deleting documents where {self.deletion_field}\")\n            try:\n                database = self.get_database_object(api_endpoint=self.d_api_endpoint)\n                collection = database.get_collection(self.collection_name, keyspace=database.keyspace)\n                delete_values = list({doc.metadata[self.deletion_field] for doc in documents})\n                self.log(f\"Deleting documents where {self.deletion_field} matches {delete_values}.\")\n                collection.delete_many({f\"metadata.{self.deletion_field}\": {\"$in\": delete_values}})\n            except Exception as e:\n                msg = f\"Error deleting documents from AstraDBVectorStore based on '{self.deletion_field}': {e}\"\n                raise ValueError(msg) from e\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        search_type_mapping = {\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\n        }\n\n        return search_type_mapping.get(self.search_type, \"similarity\")\n\n    def _build_search_args(self):\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\n\n        if query:\n            args = {\n                \"query\": query,\n                \"search_type\": self._map_search_type(),\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n            }\n        elif self.advanced_search_filter:\n            args = {\n                \"n\": self.number_of_results,\n            }\n        else:\n            return {}\n\n        filter_arg = self.advanced_search_filter or {}\n        if filter_arg:\n            args[\"filter\"] = filter_arg\n\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        vector_store = vector_store or self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        try:\n            search_args = self._build_search_args()\n        except Exception as e:\n            msg = f\"Error in AstraDBVectorStore._build_search_args: {e}\"\n            raise ValueError(msg) from e\n\n        if not search_args:\n            self.log(\"No search input or filters provided. Skipping search.\")\n            return []\n\n        docs = []\n        search_method = \"search\" if \"query\" in search_args else \"metadata_search\"\n\n        try:\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\n            docs = getattr(vector_store, search_method)(**search_args)\n        except Exception as e:\n            msg = f\"Error performing {search_method} in AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Retrieved documents: {len(docs)}\")\n\n        data = docs_to_data(docs)\n        self.log(f\"Converted documents to data: {len(data)}\")\n        self.status = data\n\n        return data\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "dishesinfo_1"
                ],
                "options_metadata": [
                  {
                    "records": 0,
                    "provider": null,
                    "icon": "",
                    "model": null
                  }
                ],
                "combobox": true,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "dishesinfo_1",
                "display_name": "Collection",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "content_field": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "content_field",
                "value": "",
                "display_name": "Content Field",
                "advanced": true,
                "dynamic": false,
                "info": "Field to use as the text content field for the vector store.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "d_api_endpoint": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "d_api_endpoint",
                "value": "",
                "display_name": "Database API Endpoint",
                "advanced": true,
                "dynamic": false,
                "info": "The API Endpoint for the Astra DB instance. Supercedes database selection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "deletion_field": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deletion_field",
                "value": "",
                "display_name": "Deletion Based On Field",
                "advanced": true,
                "dynamic": false,
                "info": "When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "embedding_choice": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Embedding Model",
                  "Astra Vectorize"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_choice",
                "value": "Embedding Model",
                "display_name": "Embedding Model or Astra Vectorize",
                "advanced": true,
                "dynamic": false,
                "info": "Choose an embedding model or use Astra Vectorize.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "environment": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "environment",
                "value": "",
                "display_name": "Environment",
                "advanced": true,
                "dynamic": false,
                "info": "The environment for the Astra DB API Endpoint.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "ignore_invalid_documents": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ignore_invalid_documents",
                "value": false,
                "display_name": "Ignore Invalid Documents",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to ignore invalid documents at runtime.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "keyspace": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "keyspace",
                "value": "",
                "display_name": "Keyspace",
                "advanced": true,
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Search Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of search results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_query": {
                "tool_mode": true,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "search_score_threshold": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_score_threshold",
                "value": 0,
                "display_name": "Search Score Threshold",
                "advanced": true,
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "search_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_type",
                "value": "Similarity",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "Search type to use",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "token": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "token",
                "value": "",
                "display_name": "Astra DB Application Token",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "real_time_refresh": true,
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Ingest and search documents in Astra DB",
            "icon": "AstraDB",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "Astra DB",
            "documentation": "https://docs.datastax.com/en/langflow/astra-components.html",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "hidden": null,
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "hidden": null,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "token",
              "environment",
              "api_endpoint",
              "d_api_endpoint",
              "collection_name",
              "keyspace",
              "embedding_choice",
              "embedding_model",
              "ingest_data",
              "search_query",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "advanced_search_filter",
              "autodetect_collection",
              "content_field",
              "deletion_field",
              "ignore_invalid_documents",
              "astradb_vectorstore_kwargs"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "vectorstores",
            "key": "AstraDB",
            "score": 0.007568328950209746
          },
          "showNode": true,
          "type": "AstraDB",
          "id": "AstraDB-5I9kj"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 621
        },
        "dragging": false
      },
      {
        "id": "DuckDuckGoSearchComponent-qT760",
        "type": "genericNode",
        "position": {
          "x": 385.30396305339093,
          "y": 799.3364640696409
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.tools import DuckDuckGoSearchRun\n\nfrom langflow.custom import Component\nfrom langflow.inputs import IntInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass DuckDuckGoSearchComponent(Component):\n    \"\"\"Component for performing web searches using DuckDuckGo.\"\"\"\n\n    display_name = \"DuckDuckGo Search\"\n    description = \"Search the web using DuckDuckGo with customizable result limits\"\n    documentation = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon = \"DuckDuckGo\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n            info=\"The search query to execute with DuckDuckGo\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=5,\n            required=False,\n            advanced=True,\n            info=\"Maximum number of search results to return\",\n        ),\n        IntInput(\n            name=\"max_snippet_length\",\n            display_name=\"Max Snippet Length\",\n            value=100,\n            required=False,\n            advanced=True,\n            info=\"Maximum length of each result snippet\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Text\", name=\"text\", method=\"fetch_content_text\"),\n    ]\n\n    def _build_wrapper(self) -> DuckDuckGoSearchRun:\n        \"\"\"Build the DuckDuckGo search wrapper.\"\"\"\n        return DuckDuckGoSearchRun()\n\n    def run_model(self) -> list[Data]:\n        return self.fetch_content()\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Execute the search and return results as Data objects.\"\"\"\n        try:\n            wrapper = self._build_wrapper()\n\n            full_results = wrapper.run(f\"{self.input_value} (site:*)\")\n\n            result_list = full_results.split(\"\\n\")[: self.max_results]\n\n            data_results = []\n            for result in result_list:\n                if result.strip():\n                    snippet = result[: self.max_snippet_length]\n                    data_results.append(\n                        Data(\n                            text=snippet,\n                            data={\n                                \"content\": result,\n                                \"snippet\": snippet,\n                            },\n                        )\n                    )\n        except (ValueError, AttributeError) as e:\n            error_data = [Data(text=str(e), data={\"error\": str(e)})]\n            self.status = error_data\n            return error_data\n        else:\n            self.status = data_results\n            return data_results\n\n    def fetch_content_text(self) -> Message:\n        \"\"\"Return search results as a single text message.\"\"\"\n        data = self.fetch_content()\n        result_string = \"\\n\".join(item.text for item in data)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The search query to execute with DuckDuckGo",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_results": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_results",
                "value": 5,
                "display_name": "Max Results",
                "advanced": true,
                "dynamic": false,
                "info": "Maximum number of search results to return",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_snippet_length": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_snippet_length",
                "value": 100,
                "display_name": "Max Snippet Length",
                "advanced": true,
                "dynamic": false,
                "info": "Maximum length of each result snippet",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "tools_metadata": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "name",
                      "display_name": "Tool Name",
                      "sortable": false,
                      "filterable": false,
                      "type": "text",
                      "description": "Specify the name of the tool.",
                      "disable_edit": false,
                      "edit_mode": "inline",
                      "formatter": "text"
                    },
                    {
                      "name": "description",
                      "display_name": "Tool Description",
                      "sortable": false,
                      "filterable": false,
                      "type": "text",
                      "description": "Describe the purpose of the tool.",
                      "disable_edit": false,
                      "edit_mode": "popover",
                      "formatter": "text"
                    },
                    {
                      "name": "tags",
                      "display_name": "Tool Identifiers",
                      "sortable": false,
                      "filterable": false,
                      "type": "text",
                      "description": "The default identifiers for the tools and cannot be changed.",
                      "disable_edit": true,
                      "edit_mode": "inline",
                      "formatter": "text"
                    }
                  ]
                },
                "trigger_text": "",
                "trigger_icon": "Hammer",
                "table_icon": "Hammer",
                "table_options": {
                  "block_add": true,
                  "block_delete": true,
                  "block_edit": true,
                  "block_sort": true,
                  "block_filter": true,
                  "block_hide": true,
                  "block_select": true,
                  "hide_options": true,
                  "field_parsers": {
                    "name": [
                      "snake_case",
                      "no_blank"
                    ],
                    "commands": "commands"
                  },
                  "description": "Modify tool names and descriptions to help agents understand when to use each tool."
                },
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools_metadata",
                "value": [
                  {
                    "name": "DuckDuckGoSearchComponent-fetch_content",
                    "description": "fetch_content(input_value: Message) - Search the web using DuckDuckGo with customizable result limits",
                    "tags": [
                      "DuckDuckGoSearchComponent-fetch_content"
                    ]
                  },
                  {
                    "name": "DuckDuckGoSearchComponent-fetch_content_text",
                    "description": "fetch_content_text(input_value: Message) - Search the web using DuckDuckGo with customizable result limits",
                    "tags": [
                      "DuckDuckGoSearchComponent-fetch_content_text"
                    ]
                  }
                ],
                "display_name": "Edit tools",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "real_time_refresh": true,
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              }
            },
            "description": "Search the web using DuckDuckGo with customizable result limits",
            "icon": "DuckDuckGo",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "DuckDuckGo Search",
            "documentation": "https://python.langchain.com/docs/integrations/tools/ddg",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "component_as_tool",
                "hidden": null,
                "display_name": "Toolset",
                "method": "to_toolkit",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "max_results",
              "max_snippet_length"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": true,
            "category": "tools",
            "key": "DuckDuckGoSearchComponent",
            "score": 0.007568328950209746
          },
          "showNode": true,
          "type": "DuckDuckGoSearchComponent",
          "id": "DuckDuckGoSearchComponent-qT760"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 337
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatInput-CHr6c",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-CHr6c,name:message,output_types:[Message]}",
        "target": "Prompt-iTxIw",
        "targetHandle": "{fieldName:question,id:Prompt-iTxIw,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-iTxIw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-CHr6c",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ChatInput-CHr6c{dataType:ChatInput,id:ChatInput-CHr6c,name:message,output_types:[Message]}-Prompt-iTxIw{fieldName:question,id:Prompt-iTxIw,inputTypes:[Message],type:str}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-iTxIw",
        "sourceHandle": "{dataType:Prompt,id:Prompt-iTxIw,name:prompt,output_types:[Message]}",
        "target": "Agent-TJ8WW",
        "targetHandle": "{fieldName:input_value,id:Agent-TJ8WW,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-TJ8WW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-iTxIw",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Prompt-iTxIw{dataType:Prompt,id:Prompt-iTxIw,name:prompt,output_types:[Message]}-Agent-TJ8WW{fieldName:input_value,id:Agent-TJ8WW,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseDataFrame-T7lTT",
        "sourceHandle": "{dataType:ParseDataFrame,id:ParseDataFrame-T7lTT,name:text,output_types:[Message]}",
        "target": "Prompt-iTxIw",
        "targetHandle": "{fieldName:results,id:Prompt-iTxIw,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "results",
            "id": "Prompt-iTxIw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseDataFrame",
            "id": "ParseDataFrame-T7lTT",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseDataFrame-T7lTT{dataType:ParseDataFrame,id:ParseDataFrame-T7lTT,name:text,output_types:[Message]}-Prompt-iTxIw{fieldName:results,id:Prompt-iTxIw,inputTypes:[Message],type:str}",
        "animated": false,
        "className": ""
      },
      {
        "source": "File-n6y94",
        "sourceHandle": "{dataType:File,id:File-n6y94,name:data,output_types:[Data]}",
        "target": "SplitText-uoR9j",
        "targetHandle": "{fieldName:data_inputs,id:SplitText-uoR9j,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-uoR9j",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "File",
            "id": "File-n6y94",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__File-n6y94{dataType:File,id:File-n6y94,name:data,output_types:[Data]}-SplitText-uoR9j{fieldName:data_inputs,id:SplitText-uoR9j,inputTypes:[Data],type:other}",
        "animated": false,
        "className": ""
      },
      {
        "source": "SplitText-uoR9j",
        "sourceHandle": "{dataType:SplitText,id:SplitText-uoR9j,name:chunks,output_types:[Data]}",
        "target": "AstraDB-4xL8y",
        "targetHandle": "{fieldName:ingest_data,id:AstraDB-4xL8y,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "AstraDB-4xL8y",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-uoR9j",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__SplitText-uoR9j{dataType:SplitText,id:SplitText-uoR9j,name:chunks,output_types:[Data]}-AstraDB-4xL8y{fieldName:ingest_data,id:AstraDB-4xL8y,inputTypes:[Data],type:other}",
        "animated": false,
        "className": ""
      },
      {
        "source": "NVIDIAEmbeddingsComponent-dJRxN",
        "sourceHandle": "{dataType:NVIDIAEmbeddingsComponent,id:NVIDIAEmbeddingsComponent-dJRxN,name:embeddings,output_types:[Embeddings]}",
        "target": "AstraDB-4xL8y",
        "targetHandle": "{fieldName:embedding_model,id:AstraDB-4xL8y,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "AstraDB-4xL8y",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "NVIDIAEmbeddingsComponent",
            "id": "NVIDIAEmbeddingsComponent-dJRxN",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "xy-edge__NVIDIAEmbeddingsComponent-dJRxN{dataType:NVIDIAEmbeddingsComponent,id:NVIDIAEmbeddingsComponent-dJRxN,name:embeddings,output_types:[Embeddings]}-AstraDB-4xL8y{fieldName:embedding_model,id:AstraDB-4xL8y,inputTypes:[Embeddings],type:other}",
        "animated": false,
        "className": ""
      },
      {
        "source": "NVIDIAEmbeddingsComponent-LEv6l",
        "sourceHandle": "{dataType:NVIDIAEmbeddingsComponent,id:NVIDIAEmbeddingsComponent-LEv6l,name:embeddings,output_types:[Embeddings]}",
        "target": "AstraDB-5I9kj",
        "targetHandle": "{fieldName:embedding_model,id:AstraDB-5I9kj,inputTypes:[Embeddings],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "AstraDB-5I9kj",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "NVIDIAEmbeddingsComponent",
            "id": "NVIDIAEmbeddingsComponent-LEv6l",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "xy-edge__NVIDIAEmbeddingsComponent-LEv6l{dataType:NVIDIAEmbeddingsComponent,id:NVIDIAEmbeddingsComponent-LEv6l,name:embeddings,output_types:[Embeddings]}-AstraDB-5I9kj{fieldName:embedding_model,id:AstraDB-5I9kj,inputTypes:[Embeddings],type:other}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-CHr6c",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-CHr6c,name:message,output_types:[Message]}",
        "target": "AstraDB-5I9kj",
        "targetHandle": "{fieldName:search_query,id:AstraDB-5I9kj,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "search_query",
            "id": "AstraDB-5I9kj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-CHr6c",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ChatInput-CHr6c{dataType:ChatInput,id:ChatInput-CHr6c,name:message,output_types:[Message]}-AstraDB-5I9kj{fieldName:search_query,id:AstraDB-5I9kj,inputTypes:[Message],type:str}",
        "animated": false,
        "className": ""
      },
      {
        "source": "AstraDB-5I9kj",
        "sourceHandle": "{dataType:AstraDB,id:AstraDB-5I9kj,name:dataframe,output_types:[DataFrame]}",
        "target": "ParseDataFrame-T7lTT",
        "targetHandle": "{fieldName:df,id:ParseDataFrame-T7lTT,inputTypes:[DataFrame],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "df",
            "id": "ParseDataFrame-T7lTT",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AstraDB",
            "id": "AstraDB-5I9kj",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          }
        },
        "id": "xy-edge__AstraDB-5I9kj{dataType:AstraDB,id:AstraDB-5I9kj,name:dataframe,output_types:[DataFrame]}-ParseDataFrame-T7lTT{fieldName:df,id:ParseDataFrame-T7lTT,inputTypes:[DataFrame],type:other}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Agent-TJ8WW",
        "sourceHandle": "{dataType:Agent,id:Agent-TJ8WW,name:response,output_types:[Message]}",
        "target": "ChatOutput-kVQPF",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-kVQPF,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-kVQPF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-TJ8WW",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Agent-TJ8WW{dataType:Agent,id:Agent-TJ8WW,name:response,output_types:[Message]}-ChatOutput-kVQPF{fieldName:input_value,id:ChatOutput-kVQPF,inputTypes:[Message],type:str}",
        "animated": false,
        "className": ""
      },
      {
        "source": "DuckDuckGoSearchComponent-qT760",
        "sourceHandle": "{dataType:DuckDuckGoSearchComponent,id:DuckDuckGoSearchComponent-qT760,name:component_as_tool,output_types:[Tool]}",
        "target": "Agent-TJ8WW",
        "targetHandle": "{fieldName:tools,id:Agent-TJ8WW,inputTypes:[Tool],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-TJ8WW",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "DuckDuckGoSearchComponent",
            "id": "DuckDuckGoSearchComponent-qT760",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "xy-edge__DuckDuckGoSearchComponent-qT760{dataType:DuckDuckGoSearchComponent,id:DuckDuckGoSearchComponent-qT760,name:component_as_tool,output_types:[Tool]}-Agent-TJ8WW{fieldName:tools,id:Agent-TJ8WW,inputTypes:[Tool],type:other}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 805.8169741601932,
      "y": 77.6037676045016,
      "zoom": 0.5671332820839402
    }
  },
  "description": "Create, Curate, Communicate with Langflow.",
  "name": "Receipe_rag_project",
  "last_tested_version": "1.1.4.post1",
  "endpoint_name": null,
  "is_component": false
}